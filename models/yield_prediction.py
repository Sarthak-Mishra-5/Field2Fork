# -*- coding: utf-8 -*-
"""yield prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nlKDpzGl9qx07arXUeo2d6cyXuWeL0Q3
"""

df=pd.read_csv('/content/Crop-Yield-Prediction-Using-Machin-Learning-Python/yield_df.csv')





import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt

def isStr(obj):
    try:
        float(obj)
        return False
    except:
        return True
to_drop = df[df['average_rain_fall_mm_per_year'].apply(isStr)].index

df = df.drop(to_drop)

df

plt.figure(figsize=(15,20))
sns.countplot(y=df['Area'])
plt.show()

country = df['Area'].unique()
yield_per_country = []
for state in country:
    yield_per_country.append(df[df['Area']==state]['hg/ha_yield'].sum())

col = ['Year', 'average_rain_fall_mm_per_year','pesticides_tonnes', 'avg_temp', 'Area', 'Item', 'hg/ha_yield']
df = df[col]
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X

y

df.head(3)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
ohe = OneHotEncoder(drop='first')
scale = StandardScaler()

preprocesser = ColumnTransformer(
        transformers = [
            ('StandardScale', scale, [0, 1, 2, 3]),
            ('OHE', ohe, [4, 5]),
        ],
        remainder='passthrough'
)

X_train_dummy = preprocesser.fit_transform(X_train)
X_test_dummy = preprocesser.transform(X_test)

preprocesser.get_feature_names_out(col[:-1])

from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error,r2_score


models = {
    'lr':LinearRegression(),
    'lss':Lasso(),
    'Rid':Ridge(),
    'Dtr':DecisionTreeRegressor()
}
for name, md in models.items():
    md.fit(X_train_dummy,y_train)
    y_pred = md.predict(X_test_dummy)

# Importing necessary libraries

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score



# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creating a decision tree classifier
clf = DecisionTreeClassifier()

# Training the classifier on the training data
clf.fit(X_train_dummy, y_train)

# Making predictions on the testing data
y_pred = clf.predict(X_test_dummy)

# Calculating the accuracy of the classifier
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error,r2_score


models = {
    'lr':LinearRegression(),
    'lss':Lasso(),
    'Rid':Ridge(),
    'Dtr':DecisionTreeRegressor()
}
for name, md in models.items():
    md.fit(X_train_dummy,y_train)
    y_pred = md.predict(X_test_dummy)

from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Define the models
models = {
    'lr': LinearRegression(),
    'lss': Lasso(),
    'Rid': Ridge(),
    'Dtr': DecisionTreeRegressor()
}

# Initialize empty dictionaries to store evaluation metrics
mae_scores = {}
r2_scores = {}

# Loop through each model
for name, md in models.items():
    # Fit the model
    md.fit(X_train_dummy, y_train)

    # Make predictions
    y_pred = md.predict(X_test_dummy)

    # Calculate Mean Absolute Error
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores[name] = mae

    # Calculate R-squared score
    r2 = r2_score(y_test, y_pred)
    r2_scores[name] = r2

# Print the evaluation metrics for each model
for name in models.keys():
    print(f"Model: {name}")
    print(f"MAE: {mae_scores[name]}")
    print(f"R-squared: {r2_scores[name]}\n")

dtr = DecisionTreeRegressor()
dtr.fit(X_train_dummy,y_train)
dtr.predict(X_test_dummy)

def prediction(Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item):
    # Create an array of the input features
    features = np.array([[Year, average_rain_fall_mm_per_year, pesticides_tonnes, avg_temp, Area, Item]], dtype=object)

    # Transform the features using the preprocessor
    transformed_features = preprocesser.transform(features)

    # Make the prediction
    predicted_yield = dtr.predict(transformed_features).reshape(1, -1)

    return predicted_yield[0]

result = prediction(1990, 1485.0, 121.00, 16.37, 'Albania', 'Maize')

result

import pickle

filename = 'yield.sav'
pickle.dump(Linear regression, open(filename, 'wb'))

import pickle

# Assuming you have already trained and fitted a Linear Regression model named 'lr_model'
# Serialize and save the model to a file named 'LinearRegression.pickle'
filename = 'LinearRegression.pickle'
with open(filename, 'wb') as f:
    pickle.dump(LinearRegression, f)

print(f"Model saved to '{filename}'")

import pickle

# Load the saved model from the pickle file
with open('LinearRegression.pickle', 'rb') as f:
    loaded_model = pickle.load(f)