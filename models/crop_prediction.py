# -*- coding: utf-8 -*-
"""crop prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gCXBKoOUtGuLr07eMW3jDIys6vPfBeTb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import model_selection
from sklearn import preprocessing
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.ensemble import BaggingClassifier



df=pd.read_csv("/content/Crop_recommendation.csv")

df.head()

df.isnull().sum()

sns.displot(x=df['N'], bins=20,kde=True,edgecolor="black",color='black',facecolor='#ffb03b')
plt.title("Nitrogen",size=20)
plt.show()

sns.displot(x=df['humidity'], color='black',facecolor='#ffb03b',kde=True,edgecolor='black')
plt.title("Humidity",size=20)
plt.show()

sns.relplot(x='rainfall',y='temperature',data=df,kind='scatter',hue='label',height=5)
plt.show()

sns.catplot(data=df, x='label', y='ph', kind='box', height=10, aspect=20/8.27)
# plt.xticks(rotation='vertical')
plt.title("Nitrogen",size=20)
plt.show()

df.columns

x = df.drop(['label'], axis=1)
x.head()

Y = df['label']
encode = preprocessing.LabelEncoder()
y = encode.fit_transform(Y)
print("Label length: ",len(y))

x_train,x_test,y_train,y_test = model_selection.train_test_split(x,y)
print(len(x_train),len(y_train),len(x_test),len(y_test))

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
from sklearn.neighbors import KNeighborsRegressor

# Initialize the KNN regressor
knn_regressor = KNeighborsRegressor(n_neighbors=5)

# Train the KNN regressor
knn_regressor.fit(x_train, y_train)

# Predict the target values for test set
y_pred = knn_regressor.predict(x_test)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

from sklearn.metrics import mean_squared_error

# Importing necessary libraries
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score



# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Initialize the Decision Tree classifier
decision_tree_classifier = DecisionTreeClassifier(random_state=42)

# Train the Decision Tree classifier
decision_tree_classifier.fit(x_train, y_train)

# Predict the labels for test set

y_pred = decision_tree_classifier.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Importing necessary libraries
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score



# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Initialize the Random Forest classifier
random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the Random Forest classifier
random_forest_classifier.fit(x_train, y_train)

# Predict the labels for test set
y_pred = random_forest_classifier.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Importing necessary libraries
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Initialize the k-NN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5)

# Train the k-NN classifier
knn_classifier.fit(x_train, y_train)

# Predict the labels for test set
y_pred = knn_classifier.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

a={'decision tree' : {
        'model' : DecisionTreeClassifier(criterion='gini'),
        'params':{'decisiontreeclassifier__splitter':['best','random']}
    },
    'svm': {
        'model': SVC(gamma='auto',probability=True),
        'params' : {
            'svc__C': [1,10,100,1000],
            'svc__kernel': ['rbf','linear']
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params' : {
            'randomforestclassifier__n_estimators': [1,5,10]
        }
    },
   'k classifier':{
       'model':KNeighborsClassifier(),
       'params':{'kneighborsclassifier__n_neighbors':[5,10,20,25],'kneighborsclassifier__weights':['uniform','distance']}
   }
}

score=[]
details = []
best_param = {}
for mdl,par in a.items():
    pipe = make_pipeline(preprocessing.StandardScaler(),par['model'])
    res = model_selection.GridSearchCV(pipe,par['params'],cv=5)
    res.fit(x_train,y_train)
    score.append({
        'Model name':mdl,
        'Best score':res.best_score_,
        'Best param':res.best_params_
    })
    details.append(pd.DataFrame(res.cv_results_))
    best_param[mdl]=res.best_estimator_
pd.DataFrame(score)

score

predicted = best_param['random_forest'].predict(x_test)
predicted

plt.figure(figsize=(12,8))
sns.heatmap(confusion_matrix(y_test,predicted),annot=True)
plt.xlabel("Original")
plt.ylabel("Predicted")
plt.show()



"""value mapping to idnetify which crop lies in which range"""

dha2 =pd.DataFrame(Y)
code = pd.DataFrame(dha2['label'].unique())

dha = pd.DataFrame(y)
encode = pd.DataFrame(dha[0].unique())
refer = pd.DataFrame()
refer['code']=code
refer['encode']=encode
refer

from sklearn.ensemble import RandomForestClassifier
import pickle

# Assuming you have your data and labels ready for training
# X_train, y_train = ...

# Create and train the RandomForestClassifier model
random_forest_classifier = RandomForestClassifier()
random_forest_classifier.fit(x_train, y_train)

# Save the model to a file
with open('random_forest_model.pickle', 'wb') as f:
    pickle.dump(random_forest_classifier, f)

print("Model saved to 'random_forest_model.pickle'")

from pydantic import BaseModel, conlist
from typing import List


class Iris(BaseModel):
    data: List[conlist(int)]

import pickle
import logging
from fastapi import FastAPI


app = FastAPI(title="ML Models as API on Google Colab", description="with FastAPI and ColabCode", version="1.0")

# # Initialize logging
# my_logger = logging.getLogger()
# my_logger.setLevel(logging.DEBUG)
# logging.basicConfig(level=logging.DEBUG, filename='logs.log')

model = None

@app.on_event("startup")
def load_model():
    global model
    model = pickle.load(open("'random_forest_model.pickle", "rb"))

@app.post("/api", tags=["prediction"])
async def get_predictions(iris: Iris):
    try:
        data = dict(df)['data']
        print(data)

        prediction = list(map(lambda x: iris_types[x], model.predict(data).tolist()))
        log_proba = model.predict_log_proba(data).tolist()
        return {"prediction": prediction, "log_proba": log_proba}
    except:
        my_logger.error("Something went wrong!")
        return {"prediction": "error"}

!pip install cc

import pickle

# Load the saved model from the pickle file
with open('random_forest_model.pickle', 'rb') as f:
    loaded_model = pickle.load(f)

m=loaded_model.predict([[85,58,41,21.770462,80.319644,7.038096,226.655537]])

m

df.columns

!pip install fastapi
!pip install uvicorn
!pip install pickle5
!pip install pydantic
!pip install scikit-learn
!pip install requests
!pip install pypi-json
!pip install pyngrok
!pip install nest-asyncio

from fastapi import FastAPI
from pydantic import BaseModel
import pickle
import json
import uvicorn
from pyngrok import ngrok
from fastapi.middleware.cors import CORSMiddleware
import nest_asyncio

app = FastAPI()

origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class model_input(BaseModel):

    N : int
    P : int
    K : int
    temperature: int
    humidity : int
    pH: float
    rainfall : float
    label : int

!pip install colabcode
!pip install fastapi

from colabcode import ColabCode
from fastapi import FastAPI

cc = ColabCode(port=12000, code=False)

app = FastAPI()

@app.get("/")
async def read_root():
  return {"message": "Subscribe to @1littlecoder"}

cc.run_app(app=app)

pickle.dump(model_f, open("random_forest_model.pickle", 'wb'", "wb"))

pickle.dump(model_f, open("random_forest_model.pickle", 'wb'))

!pip install fastapi
!pip install uvicorn
!pip install pickle5
!pip install pydantic
!pip install scikit-learn
!pip install requests
!pip install pypi-json
!pip install pyngrok
!pip install nest-asyncio

from fastapi import FastAPI
from pydantic import BaseModel
import pickle
import json
import uvicorn
from pyngrok import ngrok
from fastapi.middleware.cors import CORSMiddleware
import nest_asyncio

app = FastAPI()

origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class model_input(BaseModel):

    N: int
    P : int
    K : int
    temperature: int
    humidity : int
    pH : float
    rainfall : float
    label : int

df.columns

crop_model = pickle.load(open('random_forest_model.pickle', 'rb'))

@app.post('/diabetes_prediction')
def diabetes_predd(input_parameters : model_input):

    input_data = input_parameters.json()
    input_dictionary = json.loads(input_data)

    preg = input_dictionary['N']
    glu = input_dictionary['P']
    bp = input_dictionary['K']
    skin = input_dictionary['temperature']
    insulin = input_dictionary['humidity']
    bmi = input_dictionary['pH']
    dpf = input_dictionary['rainfall']
    age = input_dictionary['label']


    input_list = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall','label']

    prediction = crop_model.predict([input_list])

ngrok_tunnel = ngrok.connect(8000)
print('Public URL:', ngrok_tunnel.public_url)
nest_asyncio.apply()
uvicorn.run(app, port=8000)

!pip install flask_ngrok
!pip install pyngrok==4.1.1

from flask import Flask,request,jsonify,render_template

import pickle

app=Flask(__name__)

model=pickle.load(open("random_forest_model.pickle","rb"))

@app.route("/")
def home():
  return render_template("index.html")

@app.route("/predict",method=["post"])
def predict():

from flask import Flask, request, jsonify
import pickle

# Load the model
with open("random_forest_model.pickle", "rb") as f:
    model = pickle.load(f)

app = Flask(__name__)

@app.route('/')
def home():
    return 'Random Forest Model API'

@app.route('/predict', methods=['POST'])
def predict():
    # Get data from request
    data = request.get_json(force=True)

    # Predict
    prediction = model.predict([list(data.values())])

    # Return the prediction
    return jsonify(prediction[0])

if __name__ == '__main__':
    app.run(debug=True)

import numpy as np
from flask import Flask, request, render_template
import pickle

app = Flask(__name__)
model = pickle.load(open("random_forest_model.pickle", 'rb'))

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/getprediction',methods=['POST'])
def getprediction():

    input = [float(x) for x in request.form.values()]
    final_input = [np.array(input)]
    prediction = model.predict(final_input)

    return render_template('index.html', output='Predicted Weight in KGs :{}'.format(prediction))


if __name__ == "__main__":
    app.run(debug=True)











